{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¤– ML Project Template\n",
    "\n",
    "Complete machine learning pipeline template. From data to deployed model!\n",
    "\n",
    "**Perfect for**: Classification, Regression, or any supervised learning project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Import & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¼ Data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ğŸ“Š Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ğŸ¤– Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error, r2_score\n",
    "\n",
    "# âš™ï¸ Config\n",
    "np.random.seed(42)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "print(\"ğŸš€ ML Environment Ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¥ Data Loading & Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“ Load your dataset\n",
    "# df = pd.read_csv('your_data.csv')\n",
    "\n",
    "# ğŸ§ª Demo with built-in dataset\n",
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, \n",
    "                          n_redundant=2, n_classes=2, random_state=42)\n",
    "\n",
    "# Create DataFrame for easier handling\n",
    "feature_names = [f'feature_{i}' for i in range(X.shape[1])]\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "print(f\"ğŸ“Š Dataset: {df.shape[0]} rows, {df.shape[1]-1} features\")\n",
    "print(f\"ğŸ¯ Target distribution:\")\n",
    "print(df['target'].value_counts())\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š Basic statistics\n",
    "print(\"ğŸ“ˆ Feature Statistics:\")\n",
    "display(df.describe())\n",
    "\n",
    "# ğŸ•³ï¸ Missing values check\n",
    "print(f\"\\nğŸ•³ï¸ Missing values: {df.isnull().sum().sum()}\")\n",
    "\n",
    "# ğŸ“Š Target distribution visualization\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "df['target'].value_counts().plot(kind='bar', color=['skyblue', 'lightcoral'])\n",
    "plt.title('Target Distribution')\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Feature correlations\n",
    "plt.subplot(1, 3, 2)\n",
    "correlation_matrix = df.select_dtypes(include=[np.number]).corr()\n",
    "sns.heatmap(correlation_matrix, cmap='coolwarm', center=0, square=True)\n",
    "plt.title('Feature Correlations')\n",
    "\n",
    "# Sample feature distribution\n",
    "plt.subplot(1, 3, 3)\n",
    "df[feature_names[0]].hist(bins=20, alpha=0.7, color='green')\n",
    "plt.title(f'{feature_names[0]} Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§¹ Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¯ Separate features and target\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "print(f\"âœ… Features: {X.shape}\")\n",
    "print(f\"âœ… Target: {y.shape}\")\n",
    "\n",
    "# ğŸ”„ Handle missing values (if any)\n",
    "# X.fillna(X.median(), inplace=True)  # For numerical\n",
    "# X.fillna(X.mode().iloc[0], inplace=True)  # For categorical\n",
    "\n",
    "# ğŸ·ï¸ Encode categorical variables (if any)\n",
    "# le = LabelEncoder()\n",
    "# for col in X.select_dtypes(include=['object']).columns:\n",
    "#     X[col] = le.fit_transform(X[col])\n",
    "\n",
    "# âœ‚ï¸ Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"ğŸ“Š Training set: {X_train.shape}\")\n",
    "print(f\"ğŸ“Š Test set: {X_test.shape}\")\n",
    "\n",
    "# ğŸ“ Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"âœ… Features scaled and ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¤– Model Training & Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¯ Define models to compare\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# ğŸ“Š Train and evaluate each model\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nğŸ”§ Training {name}...\")\n",
    "    \n",
    "    # Use scaled data for LogReg, original for RF\n",
    "    if 'Logistic' in name:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'accuracy': accuracy,\n",
    "        'predictions': y_pred\n",
    "    }\n",
    "    \n",
    "    print(f\"âœ… {name} Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# ğŸ† Find best model\n",
    "best_model_name = max(results.keys(), key=lambda k: results[k]['accuracy'])\n",
    "best_model = results[best_model_name]['model']\n",
    "best_accuracy = results[best_model_name]['accuracy']\n",
    "\n",
    "print(f\"\\nğŸ† Best Model: {best_model_name} (Accuracy: {best_accuracy:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Model Evaluation & Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“‹ Detailed evaluation of best model\n",
    "best_predictions = results[best_model_name]['predictions']\n",
    "\n",
    "print(f\"ğŸ¯ Detailed Evaluation - {best_model_name}\")\n",
    "print(\"=\" * 50)\n",
    "print(classification_report(y_test, best_predictions))\n",
    "\n",
    "# ğŸ“Š Visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Model comparison\n",
    "model_names = list(results.keys())\n",
    "accuracies = [results[name]['accuracy'] for name in model_names]\n",
    "\n",
    "axes[0].bar(model_names, accuracies, color=['skyblue', 'lightcoral'])\n",
    "axes[0].set_title('Model Comparison')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Feature importance (if available)\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    feature_imp = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': best_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=True)\n",
    "    \n",
    "    axes[1].barh(feature_imp['feature'][-10:], feature_imp['importance'][-10:])\n",
    "    axes[1].set_title('Top 10 Feature Importance')\n",
    "    axes[1].set_xlabel('Importance')\n",
    "\n",
    "# Confusion matrix visualization\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, best_predictions)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[2])\n",
    "axes[2].set_title('Confusion Matrix')\n",
    "axes[2].set_xlabel('Predicted')\n",
    "axes[2].set_ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ Model Optimization (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¯ Hyperparameter tuning for best model\n",
    "print(f\"ğŸ”§ Optimizing {best_model_name}...\")\n",
    "\n",
    "if 'Random Forest' in best_model_name:\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [3, 5, 7, None],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        param_grid,\n",
    "        cv=3,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"ğŸ† Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"ğŸ¯ Best CV score: {grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    # Test optimized model\n",
    "    optimized_pred = grid_search.best_estimator_.predict(X_test)\n",
    "    optimized_accuracy = accuracy_score(y_test, optimized_pred)\n",
    "    \n",
    "    print(f\"âœ… Optimized test accuracy: {optimized_accuracy:.4f}\")\n",
    "    print(f\"ğŸ“ˆ Improvement: {optimized_accuracy - best_accuracy:.4f}\")\n",
    "\n",
    "else:\n",
    "    print(\"ğŸ’¡ Add hyperparameter tuning for your chosen model!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¾ Model Saving & Deployment Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "# ğŸ’¾ Save the best model and preprocessor\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model_filename = f'best_model_{timestamp}.joblib'\n",
    "scaler_filename = f'scaler_{timestamp}.joblib'\n",
    "\n",
    "# Save model and scaler\n",
    "joblib.dump(best_model, model_filename)\n",
    "joblib.dump(scaler, scaler_filename)\n",
    "\n",
    "print(f\"ğŸ’¾ Model saved as: {model_filename}\")\n",
    "print(f\"ğŸ’¾ Scaler saved as: {scaler_filename}\")\n",
    "\n",
    "# ğŸ§ª Test loading and prediction\n",
    "loaded_model = joblib.load(model_filename)\n",
    "loaded_scaler = joblib.load(scaler_filename)\n",
    "\n",
    "# Make a sample prediction\n",
    "sample_idx = 0\n",
    "if 'Logistic' in best_model_name:\n",
    "    sample_scaled = loaded_scaler.transform(X_test.iloc[[sample_idx]])\n",
    "    prediction = loaded_model.predict(sample_scaled)[0]\n",
    "else:\n",
    "    prediction = loaded_model.predict(X_test.iloc[[sample_idx]])[0]\n",
    "\n",
    "actual = y_test.iloc[sample_idx]\n",
    "\n",
    "print(f\"\\nğŸ§ª Test prediction:\")\n",
    "print(f\"   Predicted: {prediction}\")\n",
    "print(f\"   Actual: {actual}\")\n",
    "print(f\"   âœ… {'Correct!' if prediction == actual else 'Incorrect'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ Project Summary & Next Steps\n",
    "\n",
    "### ğŸ¯ Model Performance Summary:\n",
    "- **Best Model**: [Fill in after running]\n",
    "- **Test Accuracy**: [Fill in after running]\n",
    "- **Key Features**: [Fill in top 3-5 important features]\n",
    "\n",
    "### ğŸ”® Business Insights:\n",
    "- [ ] Key finding #1\n",
    "- [ ] Key finding #2 \n",
    "- [ ] Key finding #3\n",
    "\n",
    "### ğŸš€ Next Steps:\n",
    "- [ ] Collect more data for specific scenarios\n",
    "- [ ] Try additional algorithms (XGBoost, Neural Networks)\n",
    "- [ ] Feature engineering improvements\n",
    "- [ ] Deploy model to production\n",
    "- [ ] Set up monitoring and retraining pipeline\n",
    "\n",
    "### ğŸ“Š Technical Improvements:\n",
    "- [ ] Cross-validation for more robust evaluation\n",
    "- [ ] Advanced preprocessing techniques\n",
    "- [ ] Ensemble methods\n",
    "- [ ] Handle class imbalance (if applicable)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
